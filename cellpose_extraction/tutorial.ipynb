{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFY4fVIL9SRO"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MouseLand/course-materials/blob/main/cellpose_extraction/tutorial.ipynb)\n",
        "\n",
        "# processing two-photon calcium imaging data with Cellpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "This notebook will guide you through the stages of processing two-photon data. This is data collected from a wild-type mouse injected with GCaMP6s in layer 2/3 of primary visual cortex. The mouse was head-fixed above a ball and free to run, with no visual input (lights turned off). The recording was collected at 13Hz (there were 3 planes in the recording, 1 is included here). The recording has already been registered - in practice, you will need to run motion registration first. We will cover the subsequent steps of imaging data:\n",
        "\n",
        "1. cell detection\n",
        "2. signal extraction\n",
        "3. visualization\n",
        "\n",
        "To keep the notebook interactive, there are three types of exercises throughout\n",
        "1. QUESTION MARKS: where ????? need to be replaced by a short equation, such as a variable or a function name.\n",
        "2. DISCUSSION: have a short discussion with your colleague about this. At the end of each section, we will open the discussions to the whole group.\n",
        "3. QUIZ: multiple-choice that we take across the entire group. Keep track of your own points.\n",
        "\n",
        "**Setup:** First we will install the required packages, if not already installed. If you are on google colab, select the GPU runtime: Runtime > Change runtime type > Hardware accelerator = GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMOvTOuH9Uyv",
        "outputId": "14c49468-9f50-4bae-ddad-ca39d235dcc2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# cell segmentation\n",
        "!pip install cellpose \n",
        "# neural activity plotting\n",
        "!pip install rastermap \n",
        "# plotting\n",
        "!pip install matplotlib \n",
        "# download files from google drive\n",
        "!pip install gdown \n",
        "\n",
        "# SUGGESTION: you can hide the ouput of a code cell after running it  \n",
        "# in jupyter notebook by double-clicking on the left output of the cell \n",
        "# or in google colab with the left menu and \"Show/hide output\" \n",
        "# SUGGESTION #2: you can instead run the pip install commands in a different anaconda prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np # by far the most used library for everyday computation\n",
        "from scipy import stats # here we import a whole sub-library of stats functions\n",
        "from matplotlib import pyplot as plt # all of our plotting is done with plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "figure settings and video function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bH96eK729SRO"
      },
      "outputs": [],
      "source": [
        "# @title figure settings and functions\n",
        "import matplotlib\n",
        "import matplotlib.animation\n",
        "matplotlib.rcParams.update({\n",
        "    'axes.spines.top': False,\n",
        "    'axes.spines.right': False,\n",
        "    'legend.frameon': False,\n",
        "    'figure.figsize': (8, 8),\n",
        "})\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "def make_video(fr, fs=13, trange=[690, 710], yrange=[100, 300], xrange=[200, 400]):\n",
        "  ms = 1000 // fs\n",
        "  fig = plt.figure(figsize=(4, 4), dpi=60)\n",
        "  ax = fig.add_subplot(111)\n",
        "  im = ax.imshow(fr[0, yrange[0] : yrange[1], xrange[0] : xrange[1]],\n",
        "                 cmap=\"gray\", vmin=0, vmax=3000)\n",
        "  ax.axis(\"off\")\n",
        "  plt.close()\n",
        "  def animate(t):\n",
        "      im.set_data(fr[t + trange[0], yrange[0] : yrange[1], xrange[0] : xrange[1]])\n",
        "\n",
        "  ani = matplotlib.animation.FuncAnimation(fig, animate, frames=trange[1] - trange[0],\n",
        "                                           interval=ms)\n",
        "  return ani\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtYjjiX9KDp3"
      },
      "source": [
        "The next code cell downloads the data. You can also upload your own data to this folder on the left in the \"Files\" menu, or you can connect to your google drive (see instructions [here](https://colab.research.google.com/notebooks/io.ipynb)), which will make it easier to download the output files to your local computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-6J2maCaXZ",
        "outputId": "2fbf6d6d-a01f-4eef-8d85-38cca15523d5"
      },
      "outputs": [],
      "source": [
        "# @title download data\n",
        "import os, requests\n",
        "\n",
        "# raw data\n",
        "url = \"https://www.suite2p.org/test_data/gt1.tif\"\n",
        "\n",
        "# registered data\n",
        "fname = \"gt1_reg.tif\"\n",
        "!gdown 1i8l5BZfIQp0puKpEuIXTr9rvOuQucjIr\n",
        "\n",
        "from tifffile import imread\n",
        "data = imread(fname)\n",
        "data = data.astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "look at the shape of the tiff we downloaded and loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('imaging data of shape: ', data.shape)\n",
        "n_frames, Ly, Lx = data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uab5XBO_9SRP"
      },
      "source": [
        "## visualize the data\n",
        "\n",
        "First step when processing data is to look at it, check for artifacts, and decide how to process the data. We will make a video with 50 ex frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "kgOHvP7Qjvc4",
        "outputId": "ecb44b5b-77c1-4407-af0c-61bc033aa1df"
      },
      "outputs": [],
      "source": [
        "ani = make_video(data, fs=13, trange=[0, 50], yrange=[100,300],\n",
        "                 xrange=[200,400])\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfQoVKpdLZy1"
      },
      "outputs": [],
      "source": [
        "## DISCUSSION\n",
        "# What can you see in the recording? The bright flashing disks are cells, but what about smaller flashing dots?\n",
        "# Also, what are the black areas in the recording?\n",
        "# And what does it mean when the background behind the cells lights up?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BwkVC_Ulg2-"
      },
      "source": [
        "## choose image to segment\n",
        "\n",
        "We will calculate:\n",
        "1. mean image: mean of each pixel across all frames\n",
        "2. maximum projection image: maximum value of each pixel across all frames\n",
        "\n",
        "In calcium imaging, not all cells have baseline fluorescence, so not all cells will show up on the mean image. The max projection image will take the max across all timepoints, so cells which have large transients will pop out from the background. Compute these images below and visualize them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "Bt_QoZxGldHK",
        "outputId": "fb8a30df-210e-4555-90f6-baf5d2e4607d"
      },
      "outputs": [],
      "source": [
        "from cellpose import transforms\n",
        "\n",
        "# compute the mean image across frames in \"data\"\n",
        "mean_img = data.mean(axis=0)\n",
        "\n",
        "# compute the max image across frames in \"data\"\n",
        "max_proj = data.max(axis=0)\n",
        "\n",
        "# put the images in a dictionary for easy access\n",
        "imgs = {\"mean_img\": mean_img,\n",
        "        \"max_proj\": max_proj}\n",
        "\n",
        "for d, key in enumerate(imgs.keys()):\n",
        "  img = imgs[key].copy()\n",
        "  img = transforms.normalize99(img) # normalize for plotting\n",
        "  ax = plt.subplot(len(imgs),1,d+1)\n",
        "  ax.imshow(img, vmin=0, vmax=1, cmap=\"gray\")\n",
        "  ax.axis(\"off\"); ax.set_title(key)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHpf0-MfNL4K"
      },
      "source": [
        "### high-pass filtering the image (optional)\n",
        "\n",
        "There are changes in brightness across the field of view - you can see for example shadows of blood vessels that reduce brightness. We can reduce the contribution of these by removing the low-frequency components of the image. We do this in  the fourier domain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "ZJiGtzk6QlpN",
        "outputId": "e3e8c277-cd59-4c5b-acd9-2e60cbe0d867"
      },
      "outputs": [],
      "source": [
        "from torch.fft import fft2, ifft2, fftshift, ifftshift\n",
        "import torch\n",
        "\n",
        "# choose which image to analyze\n",
        "key = \"max_proj\"\n",
        "\n",
        "img = imgs[key].copy()\n",
        "# we subtract the mean here to remove the DC component of the image (optional)\n",
        "img_mean = img.mean()\n",
        "img -= img_mean\n",
        "\n",
        "# put image on GPU if possible\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "m_torch = torch.from_numpy(img).to(device)\n",
        "\n",
        "# compute the fft of the image\n",
        "# fft2 takes us from the pixel domain to the frequency domain\n",
        "m_fft = fft2(m_torch)\n",
        "# center the fft\n",
        "m_fft = fftshift(m_fft)\n",
        "\n",
        "# view the fft - at the center of the fft we see the low frequencies\n",
        "y_cent, x_cent = Ly//2, Lx//2\n",
        "im_fft = torch.abs(m_fft[y_cent-50 : y_cent+50, x_cent-50 : x_cent+50])\n",
        "im_fft = im_fft.cpu().numpy()\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(im_fft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbKDKsFsU107"
      },
      "source": [
        "Now we will set to zero the low-frequency values at the center of the image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "OKSo12OZSxU2",
        "outputId": "0ba107fb-50e4-40e0-f2f0-04cfbc586e98"
      },
      "outputs": [],
      "source": [
        "# high pass filter by removing the low frequencies\n",
        "hp = 8 # number of low frequencies to remove\n",
        "m_fft_hp = torch.clone(m_fft)\n",
        "m_fft_hp[y_cent-hp : y_cent+hp, x_cent-hp : x_cent+hp] = 0\n",
        "\n",
        "# view the fft - w/ low frequencies removed\n",
        "im_fft = torch.abs(m_fft_hp[y_cent-50 : y_cent+50, x_cent-50 : x_cent+50])\n",
        "im_fft = im_fft.cpu().numpy()\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(im_fft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EVR36HfU8Ed"
      },
      "source": [
        "Let's return the image to the pixel domain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54E0pm6iTDP3"
      },
      "outputs": [],
      "source": [
        "# ifft2 takes us from the frequency domain back to the pixel domain\n",
        "# (note we also need to undo the fftshift with ifftshift)\n",
        "m_ifft = torch.real(ifft2(ifftshift(m_fft_hp)))\n",
        "# return array to CPU\n",
        "m_ifft = m_ifft.cpu().numpy()\n",
        "img_filt = m_ifft + img_mean\n",
        "\n",
        "# add to dictionary\n",
        "imgs[key+\"_filt\"] = img_filt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSEyI0ZlVgUt"
      },
      "source": [
        "View the filtered image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "bvrS6OLsRBle",
        "outputId": "6cb49c56-4153-4fe6-a126-1aabe3f197f9"
      },
      "outputs": [],
      "source": [
        "img = transforms.normalize99(img_filt)\n",
        "ax = plt.subplot(111)\n",
        "ax.imshow(img, vmin=0, vmax=1, cmap=\"gray\")\n",
        "ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfHWSJixrzDX"
      },
      "outputs": [],
      "source": [
        "## DISCUSSION\n",
        "# The image looks more evenly bright, but there are still areas without cells.\n",
        "# Why might that be?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwRxObZ1o9g9"
      },
      "source": [
        "# segment images with cellpose\n",
        "\n",
        "Cellpose is an anatomical segmentation algorithm, which takes as input an image, and outputs masks corresponding to the identified cells. Cellpose does this with a deep neural network and pixel flow dynamics, both of which run much faster on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnEy4Ce2o84-",
        "outputId": "383ffc5b-7468-43f4-a492-f13554848cbf"
      },
      "outputs": [],
      "source": [
        "from cellpose import models\n",
        "\n",
        "# make a cellpose model\n",
        "model = models.CellposeModel(gpu=True, # will use gpu if available\n",
        "                             model_type=\"cyto3\") # model type for cells (cytoplasm)\n",
        "\n",
        "# choose which image to segment\n",
        "img = imgs[\"max_proj_filt\"].copy()\n",
        "\n",
        "# run cellpose\n",
        "masks, flows, styles = model.eval(img, \n",
        "                                  channels=[0,0], # grayscale\n",
        "                                  diameter=8, # ~ diameter of cells in pixels\n",
        "                                )\n",
        "print(f\"# of cells found: {masks.max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHUdQqdbgHaR"
      },
      "source": [
        "View the masks - each pixel is assigned a number: 0 = background (no cells), 1 = cell1, 2 = cell2 ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "eohuDxC_tSxP",
        "outputId": "08aa64f2-bc42-40a2-e4c9-0796187cb644"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,4))\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(masks[:,:300], cmap=\"magma\")\n",
        "plt.title(\"masks\"); plt.axis(\"off\")\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(masks[:,:300]>0, cmap=\"magma\")\n",
        "plt.title(\"masks > 0\"); plt.axis(\"off\")\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(flows[1][0][:,:300], cmap=\"bwr\")\n",
        "plt.title(\"Cellpose flows in Y\"); plt.axis(\"off\")\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(flows[1][1][:,:300], cmap=\"bwr\")\n",
        "plt.title(\"Cellpose flows in X\"); plt.axis(\"off\")\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AayJSUHBgoPS"
      },
      "source": [
        "Plot outlines for each cell on top of image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "WJewt7r0qKIk",
        "outputId": "5610ede6-a76e-4920-eccb-a9bb4a3ba400"
      },
      "outputs": [],
      "source": [
        "from cellpose import utils\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "outlines = utils.outlines_list(masks)\n",
        "img_norm = transforms.normalize99(img.copy())\n",
        "ax = plt.subplot(111)\n",
        "ax.imshow(img_norm, vmin=0.05, vmax=0.85, cmap=\"gray\")\n",
        "ax.axis(\"off\")\n",
        "for o in outlines:\n",
        "  ax.plot(o[:,0], o[:,1], lw=1, color=\"r\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyc0A9ejiUls"
      },
      "outputs": [],
      "source": [
        "## QUIZ:\n",
        "# Why does Cellpose predict flows instead of 0, 1, 2, 3 etc for each mask?\n",
        "# (A) The numbers for a given mask are meaningless - they can be permuted.\n",
        "# (B) By running the dynamics steps on the flows, pixels will converge to cell centers for segmentation.\n",
        "# (C) The flow representations enable representation of non-convex shapes.\n",
        "# (D) All of the above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_xjxyttvEun"
      },
      "source": [
        "# extract signals across time\n",
        "\n",
        "We have a mask for each cell - now we want to compute the activity in each of these masks across time. For this we will sum the pixels in each mask on each frame of the recording $D_t$, with some weighting for each pixel. For an example cell with $M$ mask pixels $x_m$ and $y_m$, and weights $w_m$, the fluorescence trace at time $t$ corresponds to:\n",
        "\n",
        "$$f_t = \\sum^{M}_{m=1} w_p D_t[x_m, y_m]. $$\n",
        "\n",
        "We can reformulate this as a dot product between a mask vector and $D_t$. The mask vector (as a matrix) is $\\vec{c}[x_m,y_m] = w_m$ for pixels inside the mask, and $\\vec{c}[x,y]=0$ for all other pixels. We can then flatten $\\vec{c}$ and $D_t$ and perform a dot product between the two vectors, over all pixels $p$ in the image:\n",
        "\n",
        "$$f_t = \\sum^{L_yL_x}_{p=0} \\vec{c}[p]\\, D_t[p] = \\vec{c} \\cdot D_t $$\n",
        "\n",
        "We compute this for each timepoint, which makes it a vector-matrix multiplication, where $D$ is timepoints by pixels:\n",
        "\n",
        "$$ \\vec{f} = \\vec{c} D^\\top$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo9wetJAONvv"
      },
      "source": [
        "## cell fluorescence\n",
        "\n",
        "First, let's compute this mask vector $\\vec{c}$ for each cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stJ5CN3UvSUK"
      },
      "outputs": [],
      "source": [
        "# image used for finding cell masks\n",
        "img_cells = img.copy()\n",
        "\n",
        "# cell masks which were found\n",
        "cell_masks = masks.copy()\n",
        "Ly, Lx = cell_masks.shape\n",
        "n_cells = cell_masks.max() # number of cells found\n",
        "\n",
        "# matrix where each element is an image with one cell mask\n",
        "cell_pix = np.zeros((n_cells, Ly, Lx), \"float32\")\n",
        "for n in range(n_cells):\n",
        "  # find the pixels of the cell mask\n",
        "  ypix, xpix = np.nonzero(cell_masks == (n+1))\n",
        "\n",
        "  # weight each pixel by the image intensity\n",
        "  w = img_cells[ypix, xpix]\n",
        "  w /= w.sum()\n",
        "\n",
        "  # put the weighted pixels in the matrix\n",
        "  cell_pix[n, ypix, xpix] = w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKt9xY2HRf-8"
      },
      "source": [
        "View example cell_pix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "bnLevXI5Rhgz",
        "outputId": "9acdbc8c-7d40-4d98-ee8d-d8155930a7bb"
      },
      "outputs": [],
      "source": [
        "n = 200\n",
        "plt.imshow(cell_pix[n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76T9lSBezyM0"
      },
      "outputs": [],
      "source": [
        "## QUIZ:\n",
        "# What is the sum of the weights for each cell? Why did we set it this way?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmNkcCsQwZmA"
      },
      "source": [
        "Now we want to compute the fluorescence trace for each cell $i$:\n",
        "$$ \\vec{f} = \\vec{c}_i D^\\top.$$\n",
        "\n",
        "For all cells,\n",
        "\n",
        "$$ F = [\\vec{c}_1 D^\\top \\,\\,\\, \\vec{c}_2 D^\\top \\,...\\, \\vec{c}_n D^\\top]. $$\n",
        "\n",
        "This is equivalent to a matrix multiplication between $C$ and $D$, where each row $i$ of $C$ is $\\vec{c}_i$:\n",
        "\n",
        "$$ F = CD^\\top.$$\n",
        "\n",
        "This will require reshaping ``cell_pix`` and ``data`` to be 2D arrays, where the second dimension for each is the total number of pixels (Ly * Lx). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MWQV_lYwcjO",
        "outputId": "a494ae33-0a33-4a43-d42b-5997ac912ae5"
      },
      "outputs": [],
      "source": [
        "print(data.shape, cell_pix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reshape ``cell_pix`` and ``data``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reshape cell_pix to be n_cells by number of pixels\n",
        "cell_pix_flat = cell_pix.reshape(n_cells, -1)\n",
        "\n",
        "# reshape data to be n_frames by number of pixels\n",
        "data = data.reshape(n_frames, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform matrix multiplication to get the fluorescence traces for each cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "F = cell_pix_flat @ data.T\n",
        "\n",
        "print(F.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50mCH6e7xBY3"
      },
      "source": [
        "Plot the fluorescence traces:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "xjih3KaVwnz6",
        "outputId": "076484b8-fda3-4637-98ca-76aacaa7aba8"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "for n in range(10):\n",
        "  plt.plot(zscore(F[n]) - n*5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL492yuFxMYV"
      },
      "source": [
        "Matrix multiplication will be faster on the GPU, let's implement it using pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdVCtWbNuXko"
      },
      "outputs": [],
      "source": [
        "# put data on GPU if possible\n",
        "import torch\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "d_gpu = torch.from_numpy(data).to(device)\n",
        "cell_pix_gpu = torch.from_numpy(cell_pix).to(device)\n",
        "\n",
        "# reshape data and cell_pix as above\n",
        "d_gpu = d_gpu.reshape(n_frames, -1)\n",
        "cell_pix_gpu = cell_pix_gpu.reshape(n_cells, -1)\n",
        "\n",
        "# matrix multiplication\n",
        "F = cell_pix_gpu @ d_gpu.T\n",
        "\n",
        "# return traces to CPU\n",
        "F = F.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkvM5mVKxuE2"
      },
      "source": [
        "**Bonus:** we can make this even faster using sparse matrices. Try to implement it if you're interested.\n",
        "\n",
        "Sparse matrices are created using the indices of the non-zero values in the array, and the non-zero values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmWPKH9VxK4K",
        "outputId": "c76c7f45-d62e-4c37-f4ff-97d79ddadeb9"
      },
      "outputs": [],
      "source": [
        "# get indices in flattened cell_pix\n",
        "cp = torch.nonzero(cell_pix_gpu)\n",
        "cell_ids = cp[:,0]\n",
        "pix = cp[:,1]\n",
        "\n",
        "# weights (non-zero array values)\n",
        "cell_weights = cell_pix_gpu[cell_ids, pix]\n",
        "\n",
        "# indices with weights with shape (2, n_nonzero)\n",
        "inds = torch.cat([pix.unsqueeze(0), cell_ids.unsqueeze(0)])\n",
        "\n",
        "# create sparse matrix with \"inds\" and \"cell_weights\"\n",
        "cmasks = torch.sparse_coo_tensor(inds, cell_weights,\n",
        "                                  size=(Ly*Lx, n_cells))\n",
        "cmasks = cmasks.to_sparse_csc()\n",
        "\n",
        "print(cmasks.shape)\n",
        "\n",
        "# matrix multiplication with sparse matrix\n",
        "F_sp = d_gpu @ cmasks\n",
        "\n",
        "# transpose to get n_cells by n_frames\n",
        "F_sp = F_sp.T\n",
        "# return traces to CPU\n",
        "F_sp = F_sp.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCuNsqrzeGK"
      },
      "source": [
        "Did we do it correctly? Check against original matrix-multiplication:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "lI00uvbBzaJi",
        "outputId": "1b58d97e-28dd-45cf-df58-13ac0c9a390d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(2,2))\n",
        "plt.scatter(F_sp[0], F[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcrSgeoROIFf"
      },
      "source": [
        "## neuropil fluorescence\n",
        "\n",
        "This is computed using the pixels surrounding the cell -- it is an approximation of the out-of-plane fluorescence contamination of the cell fluorescence.\n",
        "\n",
        "We will compute it using a square of pixels surrounding each cell, excluding the cell pixels themselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3wkUbWFOjjy"
      },
      "outputs": [],
      "source": [
        "# matrix where each element is an image with one neuropil mask\n",
        "neuropil_pix = np.zeros((n_cells, Ly, Lx), \"float32\")\n",
        "\n",
        "# cell_centers for each cell (will use for center of box)\n",
        "cell_centers = np.zeros((n_cells, 2), \"int\")\n",
        "\n",
        "# box size around cell center\n",
        "bsize = 30\n",
        "\n",
        "for n in range(n_cells):\n",
        "  # find pixels in cell mask\n",
        "  ypix, xpix = np.nonzero(cell_pix[n])\n",
        "  \n",
        "  # compute the cell center - we will make box around this\n",
        "  med = np.median(ypix).astype(\"int\"), np.median(xpix).astype(\"int\")\n",
        "\n",
        "  # save cell center (we will use this later for visualization)\n",
        "  cell_centers[n] = med\n",
        "\n",
        "  # set pixels in box to 1\n",
        "  neuropil_pix[n, max(0, med[0] - bsize) : min(Ly, med[0] + bsize), \n",
        "                  max(0, med[1] - bsize) : min(Lx, med[1] + bsize)] = 1\n",
        "\n",
        "# pixels to exclude from neuropil -- all pixels in cells\n",
        "ycell, xcell = np.nonzero(cell_masks > 0)\n",
        "\n",
        "# exclude cell pixels\n",
        "neuropil_pix[:, ycell, xcell] = 0\n",
        "\n",
        "# normalize so neuropil_pix for each cell will sum to 1\n",
        "neuropil_pix /= neuropil_pix.sum(axis=(1,2), keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## DISCUSSION:\n",
        "# Why did we have to take the max(0, med[0] - bsize)? What would happen if we didn't?\n",
        "\n",
        "# Hint: think about what happens if the cell is near the edge of the image, \n",
        "# and we try to make a box around it: med[0] - bsize might go negative! \n",
        "# What does negative indexing mean in Python?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-6e8QXrR0XX"
      },
      "source": [
        "View example neuropil_pix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "M8bo_l1bR0XY",
        "outputId": "67b451c5-21bf-4be6-ab94-b2609739c312"
      },
      "outputs": [],
      "source": [
        "n = 150\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(neuropil_pix[n])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cell_pix[n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5qy9y4FOS6A"
      },
      "source": [
        "Compute neuropil fluorescence with the same matrix multiplication as above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uxih3mPTHAa"
      },
      "outputs": [],
      "source": [
        "# put neuropil_pix on GPU if possible\n",
        "neuropil_pix_gpu = torch.from_numpy(neuropil_pix).to(device)\n",
        "neuropil_pix_gpu = neuropil_pix_gpu.reshape(n_cells, -1)\n",
        "\n",
        "# matrix multiplication\n",
        "Fneu = neuropil_pix_gpu @ d_gpu.T\n",
        "\n",
        "# return neuropil traces to CPU\n",
        "Fneu = Fneu.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftarrS7Tuct"
      },
      "source": [
        "Visualize neuropil + cell trace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "i-OUxVVSTxCp",
        "outputId": "1b2db406-4f02-4981-f771-da9824685e8a"
      },
      "outputs": [],
      "source": [
        "n = 150\n",
        "fmax = F[n].max()\n",
        "fig = plt.figure(figsize=(8,3))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(F[n], label=\"cell\")\n",
        "plt.plot(Fneu[n], label=\"neuropil\")\n",
        "plt.legend()\n",
        "plt.ylim([0, fmax])\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(F[n] - 0.7 * Fneu[n], color=\"k\")\n",
        "plt.ylim([0, fmax])\n",
        "plt.title(\"neuropil subtracted trace\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLDw2YRnUvd5"
      },
      "source": [
        "We will use the neuropil-corrected trace, which is the cell trace minus the neuropil trace multiplied by a scaling factor of 0.7:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoy4Lrm7Uy2H"
      },
      "outputs": [],
      "source": [
        "Fcorr = F.copy() - 0.7 * Fneu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAYwV1q51xFb"
      },
      "outputs": [],
      "source": [
        "## DISCUSSION:\n",
        "# Do you think nearby cells will be more correlated to each other than far away cells?\n",
        "# What about the neuropil of nearby cells?\n",
        "\n",
        "# We will address this in  the next section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rsxEejTyM3N"
      },
      "source": [
        "# visualize data with rastermap\n",
        "\n",
        "We will make a plot of all the neuron traces. In order to better see the activity, we will sort the neurons so that correlated neurons are put next to each other. For this, we will use our algorithm [Rastermap](github.com/mouseland/rastermap)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "xfE-HfSyyPny",
        "outputId": "33daafbd-36f3-4717-adae-a0f42dced087"
      },
      "outputs": [],
      "source": [
        "from rastermap import Rastermap # import rastermap\n",
        "\n",
        "# make Rastermap model\n",
        "# (see rastermap documentation for more details)\n",
        "rmodel = Rastermap(n_clusters=30, time_lag_window=10, bin_size=1)\n",
        "\n",
        "# fit Rastermap to neuropil-corrected traces\n",
        "rmodel.fit(Fcorr)\n",
        "\n",
        "# get the embedding of the cells\n",
        "embedding = rmodel.embedding[:,0]\n",
        "\n",
        "# embedding plot (made in Rastermap)\n",
        "X_embedding = rmodel.X_embedding\n",
        "\n",
        "# plot the embedding\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "ax = plt.subplot(111)\n",
        "ax.imshow(X_embedding, vmin=0, vmax=1, aspect=\"auto\", cmap=\"gray_r\")\n",
        "ax.set_xlabel(\"frames\")\n",
        "ax.set_ylabel(\"neurons\")\n",
        "axin = ax.inset_axes([1.02, 0, 0.02,1])\n",
        "axin.imshow(np.arange(0, n_cells)[:,np.newaxis], cmap=\"jet\", aspect=\"auto\")\n",
        "axin.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06V7SRIwWJbP"
      },
      "source": [
        "Color cells by location in rastermap to see spatial relationships:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "dBg7TZ0gVev6",
        "outputId": "6368893b-82b6-4a9a-84be-956e2edb04d8"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5,3))\n",
        "ax = plt.subplot(111)\n",
        "ax.scatter(cell_centers[:,1], cell_centers[:,0], c=embedding, cmap=\"jet\", s=4)\n",
        "ax.invert_yaxis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQebkaT8YOg5"
      },
      "source": [
        "We can also sort the neuropil traces, and see their spatial relationships:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "ZNtKHrTMYOC0",
        "outputId": "debc697c-9107-4f77-e4d8-b584ce02e8d4"
      },
      "outputs": [],
      "source": [
        "from rastermap import Rastermap\n",
        "rmodel = Rastermap(n_clusters=30, time_lag_window=10, bin_size=1)\n",
        "rmodel.fit(Fneu)\n",
        "\n",
        "# get the embedding of the neuropil traces\n",
        "embedding = rmodel.embedding[:,0]\n",
        "\n",
        "# embedding plot (made in Rastermap)\n",
        "X_embedding = rmodel.X_embedding\n",
        "\n",
        "# plot the embedding\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "ax = plt.subplot(111)\n",
        "ax.imshow(X_embedding, vmin=0, vmax=1, aspect=\"auto\", cmap=\"gray_r\")\n",
        "ax.set_xlabel(\"frames\")\n",
        "ax.set_ylabel(\"neuropil (per neuron)\")\n",
        "axin = ax.inset_axes([1.02, 0, 0.02,1])\n",
        "axin.imshow(np.arange(0, n_cells)[:,np.newaxis], cmap=\"jet\", aspect=\"auto\")\n",
        "axin.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7zqDCngYV5J"
      },
      "source": [
        "Color cells by position according to neuropil rastermap:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "FsO3UeKyYdyA",
        "outputId": "d8fd4ea6-2db1-4ffc-e2b5-c770e23b994d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5,3))\n",
        "ax = plt.subplot(111)\n",
        "ax.scatter(cell_centers[:,1], cell_centers[:,0], c=embedding, cmap=\"jet\", s=4)\n",
        "ax.invert_yaxis()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAC_0Qf3Cb6"
      },
      "outputs": [],
      "source": [
        "## DISCUSSION:\n",
        "# How is it possible that the neuropil activity (bulk inputs/dendrites/axons)\n",
        "# can be spatially organized, but NOT the cell activity?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
